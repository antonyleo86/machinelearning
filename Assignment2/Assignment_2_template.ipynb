{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "\n",
    "### Machine Learning Applications, Fall 2019\n",
    "\n",
    "* Name: Brian Hourigan\n",
    "* Student Number: 0445894\n",
    "* Email: 0445894@studentmail.ul.ie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines\n",
    "* You should solve your exercises using a Jupyter Notebook (some exercises\n",
    "require coding). In some exercises, it is requested that you write all the\n",
    "analytical steps that you made in order to get to the solution, so in this\n",
    "case you should write the steps using latex formulas in a Markdown cell.\n",
    "* Solutions should be uploaded to Sulis before the due date; they should\n",
    "be each a single PDF document (so export your notebook to PDF), and\n",
    "additional files will not be considered.\n",
    "* Students may (and should) collaboratively discuss the assignments; how-\n",
    "ever, I expect each student to write and upload their own solutions. Please\n",
    "write your full name and the names of the students (if any) you discussed\n",
    "the assignment with at the top of your solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (points 2)\n",
    "\n",
    " A <b>{Markov Chain} (MC)</b> is a graph whose edges are weighted with positive probabilities. The nodes the possible states of some process or machine. The probability on an edge from state A to state B is equal to the probability that the next state will be B if the current state is A. Since there must always be a next state, the sum of the probabilities leaving a node must be 1. \n",
    "<img src=\"MC.svg\">\n",
    "\n",
    "\n",
    " Consider the example in Figure from Wikipedia. \n",
    " The states represent whether a hypothetical stock market is exhibiting a \"bull market\", \"bear market\", or \"stagnant market\" trend during a given week. According to the figure, a bull week is followed by another bull week 90\\% of the time (that is with probability\n",
    " 0.9), a bear week 7.5\\% of the time (that is with probability\n",
    " 0.07), and a stagnant week the other 2.5\\%  of the time (that is with probability\n",
    " 0.025). Labelling the state space \\{$S_1$ = bull, $S_2$ = bear, $S_3$ = stagnant\\}, we can rewrite the graph as the following transition matrix:\n",
    "\n",
    "\n",
    "$$\n",
    "M=\\begin{bmatrix}\n",
    "p(S_1|S_1) &p(S_2|S_1)&p(S_3|S_1)\\\\\n",
    "p(S_1|S_2) &p(S_2|S_2)&p(S_3|S_2)\\\\\n",
    "p(S_1|S_3) &p(S_2|S_3)&p(S_3|S_3)   \n",
    "  \\end{bmatrix}=\\begin{bmatrix}\n",
    "0.9&0.075&0.025\\\\\n",
    "0.15&0.8&0.05\\\\\n",
    "0.25&0.25&0.5\n",
    "     \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "The first row tells us the probability of going from state $S_1$ to states\n",
    "$S_1$, $S_2$ or $S_3$.\n",
    "\n",
    "<b>(a)</b> Assume that today the market is in state $S_1$,\n",
    " what is the probability that it will be in state $S_2$ after 1 week?\n",
    " \n",
    "<b>(b)</b>  Assume that today the market is in state $S_1$,\n",
    " what is the probability that it will be in state $S_2$ after 2 weeks?\n",
    " \n",
    "<b>(c)</b> Assume that today the market is in state $S_1$ with probability\n",
    "\n",
    "  $0.625$ and in state $S_2$ with probability $0.3125$.\n",
    " what is the probability that it will be in state $S_1$ after two weeks?\n",
    "\n",
    "<b>(d)</b> This is not a question, it is just a note. The stationary probability of a MC is defined as the row\n",
    " vector of probabilities $x=[x_1,x_2,x_3]=[p(S_1),p(S_2),p(S_3)]$ such that\n",
    " $$\n",
    " x=x\\,M\n",
    " $$\n",
    " It is the probability that the MC converges to after infinite transactions.\n",
    "In this example this probability is $x=[x_1,x_2,x_3]=[p(S_1),p(S_2),p(S_3)]=[0.625, 0.3125, 0.0625 ]$).\n",
    "\\end{description}\n",
    "You need to write the steps (probability formulas you used step-by-step) that you made in order to get to the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 1(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 1(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 1(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 1(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 (points 2)\n",
    "\n",
    "One of the reasons why Google is such an effective search engine is the PageRank algorithm developed by Googleâ€˜s founders, Larry Page and Sergey Brin. PageRank is determined entirely by the link structure of the World Wide Web. It is recomputed about once a month and does not involve the actual content of any Web pages or individual queries.\n",
    "\n",
    "Imagine surfing the Web, going from page to page by randomly choosing an outgoing link from one page to get to the next.\n",
    "\n",
    "The limiting probability that an infinitely dedicated random surfer visits any particular page is its PageRank. Google models the network of Web pages by a Markov chain. It regards the network as a huge Markov Chain, where every state is a page.\n",
    "The conclusion we will arrive at is that the page ranks are proportional to the stationary probabilities of the states in the Markov chain.\n",
    "\n",
    "That is, if you wander around the Web pages randomly according to this Markov chain, after a long time, the probability of visiting any page at any time converges, and this probability is not affected by how you start your navigation.\n",
    "The higher the probability is, the higher the rank of the page will be.\n",
    "\n",
    "Consider the simplified WWW in figure, it has 4 web-pages that correspond to 4 different news-site (CNN, HP, NYT and WP). Inside the pages, in blue, you can see the links to the other pages. For instance in page 1, there are 7 links, 2/7 are to CNN, 1/7 to HP, 3/7 to NYT and 1/7 to WP.\n",
    "\n",
    "Simplified World Wide Web (only 4 pages)\n",
    "<img src=\"surfer.png\">\n",
    "\n",
    "\n",
    "<b>a</b> Write a Python script that simulates a random surfer that navigates this simplified Web going from page to page by randomly choosing an\n",
    "outgoing link from one page to get to the next (adapt the code we used in the first Lab practice -- in particular you can use FiniteRV in Sympy). Add a counter $C=[c_{CNN},c_{HP},c_{NYT},c_{WP}]$ that counts the number of times the surfer visits the four pages and show that when the number of total clicks becomes large then  $C/(c_{CNN}+c_{HP}+c_{NYT}+c_{WP})$ converges to a specific vector of probability. This vector gives the Pagerank.\n",
    "\n",
    "\n",
    "<b>b</b> Can you explain why NYT has the highest Pagerank?\n",
    "Write the matrix $M$ (see Exercise 1) for the Markov Chain associated to our simplified WWW. and compute analytically the stationary probability of the MC\n",
    " $x=xP$, where $x=[x_1,x_2,x_3,x_4]=[p(CNN),p(HP),p(NYT),P(WP)]$.\n",
    "\n",
    "Note that this way of surfing the web can lead to dead ends at pages with no outgoing links, or cycles around cliques of interconnected pages.\n",
    "So, a certain fraction of the time, Google PageRank algorithm simply chooses a random page from the Web (we ignore this aspect).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 2(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 (points 2)\n",
    "\n",
    "\n",
    "Assume that the continuous variable $x$ with domain $ \\textrm{dom}(x) =[0,1]$\n",
    "is Uniform distributed, that is its PDF is:\n",
    "$$\n",
    "p(x) = 1 \\text{ for } x\\in[0,1] \\text{ and } p(x) = 0 \\text{ for } x\\notin[0,1]\n",
    "$$\n",
    "We can write it more compactly as \n",
    "$$\n",
    "p(x)=I_{[0,1]}(x)\n",
    "$$\n",
    "where $I_{[0,1]}(x)$ is the indicator function, that is\n",
    "$I_{[0,1]}(x)=1$ if $x \\in [0,1]$ and $0$ otherwise.\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "<b>(a)</b> Compute the probability that $x$ is greater than $0.5$, that\n",
    " is\n",
    " $$\n",
    " P(x\\geq 0.5)=\\int_{0.5}^1 p(x) dx = \\int_{0.5}^1 I_{[0,1]}(x) dx=\\int_{0.5}^1  dx = ?\n",
    " $$<br/><br/>\n",
    "<b>(b)</b> Compute  \n",
    " $$\n",
    " E[x]=\\int_{0}^1 x p(x) dx=\\int_{0}^1 x I_{[0,1]}(x) dx =\\int_{0}^1 x  dx = ?\n",
    " $$ \n",
    " and \n",
    " $$\n",
    " E[x^2]=\\int_{0}^1 x^2 p(x) dx=\\int_{0}^1 x^2 I_{[0,1]}(x) dx =\\int_{0}^1 x^2  dx = ?\n",
    " $$\n",
    " <br/><br/>\n",
    "<b>(c)</b> Compute the variance $x$, that is $E[(x-E[x])^2]$.\n",
    "\n",
    "You need to write the steps  that you made in order to get to the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 3(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 3(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 3(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 (points 2)\n",
    "\n",
    "The cumulative distribution function (CDF) of a continuous variable is\n",
    "defined as\n",
    "$$\n",
    "F(\\textsf{x})=P(x\\leq \\textsf{x})=\\int_{-\\infty}^{\\textsf{x}} p(x)dx\n",
    "$$\n",
    "</br></br>\n",
    "\n",
    "<b>(a)</b> Compute  the CDF of the uniform distribution in $[0,1]$\n",
    " whose PDF is $p(x)=I_{[0,1]}(x)$ (it was defined in the previous exercise).\n",
    " \n",
    "</br></br>\n",
    "<b>(b)</b> Compute the CDF of the exponential distribution whose PDF is $p(x)=\t\\lambdaâ€‰e^{-\\lambda x}$ for $x \\in \\text{dom}(x)=[0,\\infty)$ and $p(x)=0$ otherwise. We can write it more compactly as\n",
    " $p(x)=I_{[0,\\infty)}(x) \\lambdaâ€‰e^{-\\lambda x}$. Note that $\\lambda\\geq0$ is a parameter.\n",
    "</br></br>\n",
    "\n",
    "<b>(c)</b>The CDF can be used to sample any distribution\n",
    "```{python}\n",
    "import numpy as np\n",
    "from scipy.optimize import bisect\n",
    "def sample(CDF,dom, size=100):\n",
    "    X=[]\n",
    "    for i in range(size):\n",
    "        u = np.random.rand(1)\n",
    "        #invert cdf using bisection method\n",
    "        def fun(x):\n",
    "            return u-CDF(x)\n",
    "        res=bisect(fun, dom[0],dom[1])\n",
    "        X.append(res)\n",
    "    return X\n",
    "```\n",
    "where \"dom\" is the domain of the continuous variable and \"CDF\"\n",
    "is the CDF function. Can you explain why/how this code works? (test it yourself\n",
    "with the uniform and exponential distribution).\n",
    "\n",
    "</br></br>\n",
    "<b>(d)</b> Sample $N$ points $\\{x_1,\\dots,x_N\\}$ from the uniform density $p(x)=I_{[0,1]}(x)$ and show that when $N$ becomes large\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{i=1}^N x_i \\rightarrow E[x]\n",
    "$$\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{i=1}^N x_i^2 \\rightarrow E[x^2]\n",
    "$$\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{i=1}^N \\left(x_i -\\frac{1}{N} \\sum_{j=1}^N x_j  \\right)^2 \\rightarrow E[(x-E[x])^2]\n",
    "$$\n",
    "where $\\rightarrow$ is the symbol of a \"limit\" and means \"tends to\"\n",
    "(for $N \\rightarrow \\infty$).\n",
    "\\end{description}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 4\n",
    "\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "import pylab as plt\n",
    "from scipy.optimize import bisect\n",
    "\n",
    "def sample(CDF,dom, size=100):\n",
    "    X=[]\n",
    "    for i in range(size):\n",
    "        u = np.random.rand(1)\n",
    "        #invert cdf\n",
    "        def fun(x):\n",
    "            return u-CDF(x)\n",
    "        res=bisect(fun, dom[0],dom[1])\n",
    "        X.append(res)\n",
    "    return X\n",
    "\n",
    "def CDF(x):\n",
    "    return x\n",
    "\n",
    "plt.hist(sample(CDF,[0,10000],size=1000));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 4(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 4(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 4(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 4(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 (points 2)\n",
    "\n",
    "In this week practise,  we saw the Bayesian t-test:  a way to compare two populations.\n",
    "We can use Bayesian t-test to compare the performance of three classifiers on different datasets. In ML, we often compare classifiers' performance. The proper way to do is to use a probabilistic method, because it accounts for the uncertainty.\n",
    "It allows to answer questions like: Is it enough the number of a datasets we selected? Should we consider more datasets?\n",
    "\n",
    "The provided code (see Notebook) computes the accuracy of three classifiers on 15 generated datasets.\n",
    "\n",
    "</br></br>\n",
    "\n",
    "<b>(a)</b>Use the provided Scores and apply the Bayesian t-test to compare the performance of the classifier\n",
    " 1 vs.\\ 2. What can you say?\n",
    "</br></br>\n",
    "\n",
    "<b>(b)</b> Use the provided Scores  and apply the Bayesian t-test to compare the performance of the classifier\n",
    "1 vs.\\ 3. What can you say?\n",
    "\n",
    "Be careful when you selected the parameters of the priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 5\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "#don't worry about this code, for the exercise you only need to know\n",
    "#the table at the end (called \"Scores\")\n",
    "\n",
    "classifiers = [GaussianNB(), QuadraticDiscriminantAnalysis(), SVC(gamma=2, C=1)]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable1 = (X, y)\n",
    "\n",
    "X, y = make_classification(n_features=3, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable2 = (X, y)\n",
    "\n",
    "X, y = make_classification(n_features=5, n_redundant=0, n_informative=3,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable3 = (X, y)\n",
    "\n",
    "X, y = make_classification(n_features=4, n_redundant=0, n_informative=3,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable4 = (X, y)\n",
    "\n",
    "X, y = make_classification(n_features=4, n_redundant=0, n_informative=4,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable5 = (X, y)\n",
    "\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_moons(noise=0.4, random_state=2),\n",
    "            make_moons(noise=0.2, random_state=0),\n",
    "            make_moons(noise=0.05, random_state=0),\n",
    "            make_moons(noise=0.4, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            make_circles(noise=0.1, factor=0.5, random_state=1),\n",
    "            make_circles(noise=0.2, factor=0.2, random_state=1),\n",
    "            make_circles(noise=0.2, factor=0.2, random_state=1),\n",
    "            make_circles(noise=0.2, factor=0.6, random_state=1),\n",
    "            linearly_separable1,\n",
    "             linearly_separable2,\n",
    "             linearly_separable3,   \n",
    "            linearly_separable4,\n",
    "            linearly_separable5\n",
    "            ]\n",
    "\n",
    "i = 1\n",
    "Scores=[]\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    # iterate over classifiers\n",
    "    Score=[]\n",
    "    for clf in classifiers:\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        Score.append(score)\n",
    "    Scores.append(Score)\n",
    "Scores=np.array(Scores)\n",
    "Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 5(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 5(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
